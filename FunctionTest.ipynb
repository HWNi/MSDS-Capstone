{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv\n",
    "import cPickle\n",
    "import fuzzy\n",
    "import os\n",
    "import re\n",
    "\n",
    "from calcSimScore import *\n",
    "from string_based_cluster import *\n",
    "from meta_path import *\n",
    "from custom_setting import *\n",
    "from name import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSerialization files related to name_statistics do not exist.\n",
      "\tReading in the author.csv file.\n",
      "\tFinish analysing 20000 lines of the file.\n",
      "\tFinish analysing 40000 lines of the file.\n",
      "\tFinish analysing 60000 lines of the file.\n",
      "\tFinish analysing 80000 lines of the file.\n",
      "\tFinish analysing 100000 lines of the file.\n",
      "\tReading in the paperauthor.csv file.\n",
      "\tWriting into serialization files related to name_statistics.\n",
      "\tSerialization files related to authors do not exist.\n",
      "\tReading in the author.csv file.\n",
      "\tFinish analysing 20000 lines of the file.\n",
      "\tFinish analysing 40000 lines of the file.\n",
      "\tFinish analysing 60000 lines of the file.\n",
      "\tFinish analysing 80000 lines of the file.\n",
      "\tFinish analysing 100000 lines of the file.\n",
      "\tStart recovering names\n",
      "\tFinish analysing 20000 lines of the file.\n",
      "\tFinish analysing 40000 lines of the file.\n",
      "\tFinish analysing 60000 lines of the file.\n",
      "\tFinish analysing 80000 lines of the file.\n",
      "\tFinish analysing 100000 lines of the file.\n",
      "\tFinish analysing 120000 lines of the file for removing noisy last names.\n",
      "\tFinish analysing 140000 lines of the file for removing noisy last names.\n",
      "\tFinish analysing 160000 lines of the file for removing noisy last names.\n",
      "\tFinish analysing 180000 lines of the file for removing noisy last names.\n",
      "\t\tSplit anil kumar thimmegowda --> anil kumar thimme gowda\n",
      "\t\tSplit parthasarathy satishchandra --> parthasarathy satish chandra\n",
      "\tFinish analysing 200000 lines of the file.\n",
      "\t\tSplit abbas ali vatankhah mohammadabadi --> abbas ali vatankhah mohammad abadi\n",
      "\tFinish analysing 220000 lines of the file.\n",
      "\t\tSplit h suryaprakash --> h surya prakash\n",
      "\t\tSplit aparna satyanarayan --> aparna satya narayan\n",
      "\t\tSplit mariateresa sasanelli --> maria teresa sasanelli\n",
      "\t\tSplit sundersingh shirley --> sunder singh shirley\n",
      "\tFinish analysing 240000 lines of the file.\n",
      "\t\tSplit karin hoffmann sommergruber --> karin hoffmann sommer gruber\n",
      "\t\tSplit marialetizia penza --> maria letizia penza\n",
      "\tFinish analysing 260000 lines of the file.\n",
      "\t\tSplit narendrakumar alappan --> narendra kumar alappan\n",
      "\t\tSplit fatimah b abdulkareem --> fatimah b abdul kareem\n",
      "\t\tSplit elena lopez villarrubia --> elena lopez villar rubia\n",
      "\tFinish analysing 280000 lines of the file.\n",
      "\t\tSplit mariaclaudia meli --> maria claudia meli\n",
      "\tWriting into serialization files related to name_statistics.\n",
      "\n",
      "\tWriting into serialization files related to authors.\n",
      "\n",
      "\tSerialization files related to coauthors do not exist.\n",
      "\tReading in the paperauthor.csv file.\n",
      "\tComputing the coauthor graph.\n"
     ]
    }
   ],
   "source": [
    "(name_instance_dict, id_name_dict, name_statistics, author_paper_stat, metapaths) = load_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_similar_ids_under_name(name_instance_dict, id_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cPickle.dump(name_instance_dict, open(serialization_dir + \"step2_\" + name_instance_file, \"wb\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_duplicate_groups = create_potential_duplicate_groups(name_instance_dict, author_paper_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_duplicate_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_duplicate_groups2 = local_clustering(similarity_score_dict, potential_duplicate_groups, author_paper_stat,\n",
    "                                          name_instance_dict, id_name_dict, name_statistics, metapaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_duplicate_groups = real_duplicate_groups1.union(real_duplicate_groups2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_duplicate_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
